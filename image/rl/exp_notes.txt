6_25_18-21: SI curr-prime,curr-empty,sparse-prime,sparse-empty
6_25_22-25: F curr-prime,curr-empty,sparse-prime,sparse-empty
6_25_26-29: L curr-prime,curr-empty,sparse-prime,sparse-empty
6_26_0-3: F curr-prime,curr-empty,sparse-prime,sparse-empty
6_26_4-7: R prime-bc, prime-no bc, empty-bc, empty-no bc
6_27_0-3: R no curr-2 target, no curr-10 target, curr-2 target, curr-10 target
6_27_5-10: R no curr - 2,10,inf; curr - 2,10,inf
6_27_11-16: R prime no curr - 2,10,inf; curr - 2,10,inf
6_27_17-19: R no prime no curr relabel all - 2,10,inf; curr - 2,10,inf
6_29_1: curriculum initial .01, trajectory,rewards added directly
6_29_2: curriculum initial .05, trajectory,rewards added directly
6_29_3: curriculum initial .05, joint, rewards added directly
6_29_4: curriculum initial .05, starting positions change, joint, rewards added directly
6_29_5: curriculum initial .05, starting positions change, trajectory, rewards added directly
6_30_1: joint, lr 1e-4
6_30_2: joint, lr 3e-4
6_30_3: trajectory, lr 1e-4
6_30_4: trajectory, lr 3e-4
6_30_5: joint, lr 1e-4
6_30_6-8: joint, lr 1e-4: 1/total, diff, diff**3, no noise, trajectory oracle
6_30_9-11: traj, lr 1e-4: 1/total, diff, diff**3, no noise, trajectory oracle
6_30_12-14: joint, lr 1e-4: 1/total, diff, diff**3, no noise, target oracle
6_30_15-17: traj, lr 1e-4: 1/total, diff, diff**3, no noise, target oracle
6_30_18-20: traj, lr 1e-4: 1/total, diff, diff**3, noise, trajectory oracle
7_1_0-2: traj, lr 1e-4: 1/total, diff, diff**3, noise, target oracle
7_1_3-5: joint, lr 1e-4: 1/total, diff, diff**3, noise, trajectory oracle

7_1_6-8: movinginit joint, lr 1e-4: 1/total, diff, diff**3, noise, trajectory oracle
7_1_9-11: movinginit traj, lr 1e-4: 1/total, diff, diff**3, noise, trajectory oracle
7_1_12-14: movingint joint, lr 1e-4: 1/total, diff, diff**3, noise, target oracle
7_1_15-17: movinginit traj, lr 1e-4: 1/total, diff, diff**3, noise, target oracle

7_2_0: dist_hot_cold
7_2_1: rad_hot_cold
7_2_2: dist_disc_traj
7_2_3: rad_disc_traj
7_3_0: linear
7_3_1: concave
7_3_2: convex
7_4_0: rad-hot-cold pavlov
7_4_1: rad-disc-traj pavlov
7_5_0: rad_disc_traj pavlov, new param range.
7_7_1: blank sweep four tasks
7_10_0: scratch-itch,feeding,laptop empirical user
7_11_0: discrete targets, light-switch,feeding,laptop, empirical user, curriculum
7_12_0: switch to target based control
7_13_0: dense user input during pretraining. positive examples, mixed, masking obs

test: pretraining, reward penalized
test1: pretraining, no penalty
test2: no pretraining
test3: no examples
test5: cos traj input, less inputs,
test6: hyperparam tuning
test7: dense hyperparam tuning
test8: no pretraining extended run
test9: dense input during training
test10: cocktail user input for examples
test11: only bc, no examples during online
test12: no pretraining, with examples
test13: sweep user threshold
test14: smaller replay buffer for 250 episodes
test15: dense input when close to target
test16: 50-50 replay buffer
test17: bad test advantage function
test18: advantage function 
test19: advantage function, no gradual threshold, only good demos
test20: reward function, only good demos
test21b: two target discrete categorical
test21c: lightswitch
test21d: laptop
test22a: two target discrete categorical, no target in obs
test22b: mid target delay=0
test22c: mid target delay=80
test22d: mid target delay=0 shorten pretraining
test23: fuse targets, third target test
test24: continuous target
test26: fused target, two original targets (a: target in obs, b: target not in obs)
test27: lightswitch (a: fused target-target in obs, b: fused target-target not in obs, c: actual target prediction-target not in obs)
test28: lightswitch discrete targets, q update using v
test29: lightswitch dqn policy
test30: retest policy penalty method on trajectory
test31: retest advantage function
test32: dqfd
